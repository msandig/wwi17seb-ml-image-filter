{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilden eines Models mit Original und einem Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import der notwendigen Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import des Datasets\n",
    "\n",
    "Zus채tzlich zum Laden des Datasets (2 Klassen) wird hier bereits durch den ImageDataGenerator ein Preprocessing durchgef체hrt / vorbereitet.\n",
    "Zun채chst wird versucht eine Klassifizierung durchzuf체hren, bei dem die Bilder in Graustufen geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2048 images belonging to 2 classes.\n",
      "Found 512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# path to dataset\n",
    "directory = \"./FACD_image\"\n",
    "# choosen classes (origin + filter) for classification\n",
    "classes = [\"Origin\", \"Amaro\"];\n",
    "target_size = (400,400)\n",
    "seed = 42;\n",
    "\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "    directory, data_generator, target_size=target_size, color_mode='grayscale',\n",
    "    classes=classes, class_mode='categorical', batch_size=32, shuffle=True, seed=seed,\n",
    "    follow_links=False, subset='training', interpolation='nearest', dtype=None\n",
    ")\n",
    "\n",
    "test_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "    directory, data_generator, target_size=target_size, color_mode='grayscale',\n",
    "    classes=classes, class_mode='categorical', batch_size=32, shuffle=True, seed=seed,\n",
    "    follow_links=False, subset='validation', interpolation='nearest', dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 398, 398, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 199, 199, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 197, 197, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 614656)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 614656)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1229314   \n",
      "=================================================================\n",
      "Total params: 1,248,130\n",
      "Trainable params: 1,248,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Building the CNN-Model\n",
    "input_shape = (400,400,1)\n",
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(keras.Input(shape=input_shape))\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 64.0 steps, validate for 16 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Anaconda3\\envs\\dhbw20\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Martin\\Anaconda3\\envs\\dhbw20\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/64 [==============>...............] - ETA: 1:03 - loss: 58.2603 - accuracy: 0.7480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Anaconda3\\envs\\dhbw20\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19273 bytes but only got 816. Skipping tag 700\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\Martin\\Anaconda3\\envs\\dhbw20\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5140 bytes but only got 816. Skipping tag 34377\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "C:\\Users\\Martin\\Anaconda3\\envs\\dhbw20\\lib\\site-packages\\PIL\\TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3144 bytes but only got 816. Skipping tag 34675\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 136s 2s/step - loss: 29.7040 - accuracy: 0.7637 - val_loss: 0.4136 - val_accuracy: 0.8633\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 134s 2s/step - loss: 0.3968 - accuracy: 0.8691 - val_loss: 0.3344 - val_accuracy: 0.8965\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 132s 2s/step - loss: 0.3273 - accuracy: 0.9097 - val_loss: 0.2782 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 137s 2s/step - loss: 0.2763 - accuracy: 0.9351 - val_loss: 0.1835 - val_accuracy: 0.9531\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 139s 2s/step - loss: 0.2503 - accuracy: 0.9414 - val_loss: 0.2676 - val_accuracy: 0.9551\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 141s 2s/step - loss: 0.2625 - accuracy: 0.9502 - val_loss: 0.2792 - val_accuracy: 0.9668\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 141s 2s/step - loss: 0.2585 - accuracy: 0.9521 - val_loss: 0.2588 - val_accuracy: 0.9609\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 139s 2s/step - loss: 0.1996 - accuracy: 0.9502 - val_loss: 0.1633 - val_accuracy: 0.9727\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 137s 2s/step - loss: 0.2332 - accuracy: 0.9546 - val_loss: 0.1474 - val_accuracy: 0.9688\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 138s 2s/step - loss: 0.2005 - accuracy: 0.9590 - val_loss: 0.1577 - val_accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "steps_per_epoch = 2048 / 32\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_iterator, y=None, epochs=epochs, verbose=1, callbacks=None,\n",
    "    validation_data=test_iterator, initial_epoch=0, steps_per_epoch=steps_per_epoch, validation_freq=1,\n",
    "    max_queue_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./first_model.hdf5\"\n",
    "\n",
    "model.save(\n",
    "   filepath, overwrite=True, include_optimizer=True, save_format=\"h5\",\n",
    "    signatures=None, options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.704030925640836,\n",
       " 0.3967975878622383,\n",
       " 0.3273363998159766,\n",
       " 0.27630380901973695,\n",
       " 0.25034243147820234,\n",
       " 0.2624659000430256,\n",
       " 0.2584758581360802,\n",
       " 0.19960219750646502,\n",
       " 0.2331643565557897,\n",
       " 0.20047224865993485]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.get(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
